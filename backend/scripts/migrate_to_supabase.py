
import os
import sys
import pandas as pd
from supabase import create_client, Client
from dotenv import load_dotenv

# Add parent dir to path to import gsheets service
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.services.gsheets import load_data as load_gsheets

# --- CONFIG ---
# You needs to set these in your .env file or hardcode them here temporarily
load_dotenv()
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY") # Service Role Key preferred for migration

if not SUPABASE_URL or not SUPABASE_KEY:
    print("âŒ Error: SUPABASE_URL and SUPABASE_KEY must be set in .env file")
    print("Please create a .env file in backend/ directory with:")
    print("SUPABASE_URL=...")
    print("SUPABASE_KEY=...")
    sys.exit(1)

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

SHEETS_TO_TABLES = {
    "User_Master": "users",
    "Contacts": "contacts",
    "Activities": "activities",
    "Master_Schedule": "master_schedule"
}

def clean_column_name(col: str) -> str:
    # Convert "Column Name" to "column_name"
    return col.strip().lower().replace(" ", "_").replace(".", "")

def get_sql_type(dtype):
    if pd.api.types.is_integer_dtype(dtype):
        return "bigint"
    elif pd.api.types.is_float_dtype(dtype):
        return "float"
    elif pd.api.types.is_bool_dtype(dtype):
        return "boolean"
    else:
        return "text"

def migrate_sheet(sheet_name, table_name):
    print(f"\n--- Migrating {sheet_name} -> {table_name} ---")
    
    # 1. Load Data
    try:
        df = load_gsheets(sheet_name)
        print(f" Loaded {len(df)} rows from Sheets")
    except Exception as e:
        print(f" Failed to load sheet: {e}")
        return

    if df.empty:
        print(" Sheet is empty, skipping data upload.")
        return

    # 2. Clean Columns
    df.columns = [clean_column_name(c) for c in df.columns]
    
    # 3. Generate Table Schema (DDL)
    print("\n[SQL TO RUN IN SUPABASE SQL EDITOR]:")
    print(f"CREATE TABLE IF NOT EXISTS {table_name} (")
    print("  id bigint generated by default as identity primary key,")
    print("  created_at timestamp with time zone default timezone('utc'::text, now()) not null,")
    
    for col in df.columns:
        sql_type = get_sql_type(df[col].dtype)
        print(f"  {col} {sql_type},")
    
    print(");")
    print(f"-- Enable RLS if needed (optional for backend usage)")
    print(f"alter table {table_name} enable row level security;")
    print("----------------------------------------------------\n")

    # 4. Upload Data
    # Convert to numeric where possible to avoid JSON errors
    # Split into chunks of 1000
    records = df.to_dict(orient='records')
    
    chunk_size = 1000
    total_inserted = 0
    
    print(f"Uploading {len(records)} records...")
    
    for i in range(0, len(records), chunk_size):
        chunk = records[i:i + chunk_size]
        try:
            data, count = supabase.table(table_name).insert(chunk).execute()
            # In older supabase-py versions, response structure differs. 
            # Assuming success if no exception.
            total_inserted += len(chunk)
            print(f"   Inserted {min(i + chunk_size, len(records))}/{len(records)}")
        except Exception as e:
            print(f" Error inserting chunk {i}: {e}")
            # Try converting everything to string as fallback
            try: 
                 print("   Retrying chunk as strings...")
                 chunk_str = [{k: str(v) for k, v in r.items()} for r in chunk]
                 supabase.table(table_name).insert(chunk_str).execute()
                 total_inserted += len(chunk)
            except Exception as e2:
                 print(f"   Retry failed: {e2}")

    print(f" Migration for {table_name} complete! ({total_inserted} rows)")

if __name__ == "__main__":
    print("Deprecated: This script assumes you have created the tables in Supabase.")
    print("I will print the SQL schema for you to run first if the tables don't exist.")
    
    for sheet, table in SHEETS_TO_TABLES.items():
        migrate_sheet(sheet, table)
